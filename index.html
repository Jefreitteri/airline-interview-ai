<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <title>Airline Interview AI (Locked Voice)</title>
  <style>
    body { font-family: system-ui, Arial, sans-serif; margin: 20px; }
    button { margin-right: 10px; padding: 8px 12px; }
    #status { margin: 10px 0; color: #444; }
    #log { white-space: pre-wrap; font-size: 12px; color: #333; }
  </style>
</head>
<body>
  <h1>Airline Interview AI 123 (Locked Voice)</h1>

  <button id="startBtn">Start</button>
  <button id="stopBtn" disabled>Stop</button>

  <div id="status">Idle.</div>
  <div id="log"></div>

<script>
let pc;
let localStream;
let dataChannel;
let audioEl;

const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const logEl    = document.getElementById("log");

function log(msg) {
  logEl.textContent += msg + "\n";
}

startBtn.onclick = async () => {
  startBtn.disabled = true;
  stopBtn.disabled = false;
  statusEl.textContent = "Requesting microphone…";

  // 1) get ephemeral client_secret from backend
  const tokenResp = await fetch("/api/realtime-token", { method: "POST" });
  const tokenData = await tokenResp.json();

  const ephemeralKey = tokenData?.client_secret?.value;
  if (!ephemeralKey) {
    startBtn.disabled = false;
    stopBtn.disabled = true;
    alert("Failed to get realtime token. Check Vercel logs + OPENAI_API_KEY.");
    console.log(tokenData);
    return;
  }

  // 2) WebRTC
  pc = new RTCPeerConnection();

  // Audio output from model
  audioEl = document.createElement("audio");
  audioEl.autoplay = true;
  pc.ontrack = (e) => { audioEl.srcObject = e.streams[0]; };

  // Data channel to see events/errors (optional but useful)
  dataChannel = pc.createDataChannel("oai-events");
  dataChannel.onmessage = (ev) => {
    try {
      const msg = JSON.parse(ev.data);
      // Show only errors to keep noise low
      if (msg?.type?.includes("error")) log("ERROR: " + ev.data);
    } catch {
      // ignore
    }
  };

  // Mic input
  localStream = await navigator.mediaDevices.getUserMedia({ audio: true });
  for (const track of localStream.getTracks()) pc.addTrack(track, localStream);

  // Create offer
  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);

  // 3) Send SDP to Realtime endpoint
  statusEl.textContent = "Connecting…";

  const baseUrl = "https://api.openai.com/v1/realtime";
  const model   = "gpt-4o-realtime-preview";

  const sdpResp = await fetch(`${baseUrl}?model=${encodeURIComponent(model)}`, {
    method: "POST",
    headers: {
      "Authorization": `Bearer ${ephemeralKey}`,
      "Content-Type": "application/sdp"
    },
    body: offer.sdp
  });

  const answerSDP = await sdpResp.text();
  await pc.setRemoteDescription({ type: "answer", sdp: answerSDP });

  statusEl.textContent = "Connected. Interview running.";
  log("Realtime interview started.");
};

stopBtn.onclick = () => {
  stopBtn.disabled = true;
  startBtn.disabled = false;

  if (dataChannel) {
    try { dataChannel.close(); } catch {}
    dataChannel = null;
  }

  if (pc) {
    try { pc.close(); } catch {}
    pc = null;
  }

  if (localStream) {
    localStream.getTracks().forEach(t => t.stop());
    localStream = null;
  }

  statusEl.textContent = "Stopped.";
  log("Interview stopped.");
};
</script>
</body>
</html>

