<!doctype html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Airline Interview AI (Voice)</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin: 18px; }
    button { padding: 10px 14px; margin-right: 10px; }
    #status { margin-top: 10px; opacity: 0.85; }
    #log { margin-top: 10px; white-space: pre-wrap; font-size: 12px; opacity: 0.8; max-height: 45vh; overflow:auto; background:#f6f6f6; padding:10px; border-radius:8px;}
  </style>
</head>
<body>
  <h1>Airline Interview AI (Voice)</h1>
  <button id="startBtn">Start interview</button>
  <button id="stopBtn" disabled>Stop</button>
  <div id="status">Idle</div>
  <div id="log"></div>

<script>
const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const logEl    = document.getElementById("log");
const setStatus = (s) => statusEl.textContent = s;
const log = (s) => { logEl.textContent = (logEl.textContent + s + "\n").slice(-12000); };

let pc=null, dc=null, localStream=null, audioEl=null;

const ENGLISH_TERMS = [
  "V1","V2","balanced field length","accelerate-stop distance","stabilized approach",
  "DA","MDA","contingency fuel","alternate fuel","windshear",
  "threat and error management","situational awareness","sterile cockpit",
  "RVSM","CAT I","CAT III","pilot flying","pilot monitoring"
];

const SYSTEM = `
You are a three-member airline interview panel conducting a realistic airline screening interview simulation for a pilot role.

DEFAULT LANGUAGE:
- Default language is English.
- Switch to the candidate’s requested language ONLY if the candidate explicitly asks.

TERMS:
- Keep ALL aviation/technical terms in English and do NOT translate them.
- Examples: ${ENGLISH_TERMS.join(", ")}.

OUTPUT RULES:
- Output ONLY the question requested by the client instructions.
- Ask ONE question at a time.
- Do NOT add commentary, explanations, coaching, or advice.
- No filler acknowledgements.
- If candidate asks for help: reply exactly:
  "In a real airline interview I cannot coach you. Please answer using a real example."
`;

// ===== FLOW STATE =====
const FLOW = {
  lang: "English",
  phase: 1,
  idx: 0,
  level: 2,
  transcript: [],
  // IMPORTANT:
  // - armed = we have asked a question and we are now willing to accept user transcript as the answer
  armed: false,
  awaitingId: null,
  // prevents multiple asks overlapping
  busyAsking: false,
  // gate (behavioural)
  gate: { hasExample:false, hasOutcome:false, anchors:0 }
};

const store = { stage:"", hours:"", prev:"" };

function normalize(s){ return (s||"").toLowerCase().replace(/\s+/g," ").trim(); }

function detectLanguageRequest(userText){
  const t = normalize(userText);
  if (t.includes("suomeksi") || t.includes("in finnish") || t.includes("finnish")) return "Finnish";
  if (t.includes("englanniksi") || t.includes("in english") || t.includes("english")) return "English";
  const m = t.match(/\bin ([a-zäöå]+)\b/);
  if (m && m[1]) {
    const lang = m[1].charAt(0).toUpperCase() + m[1].slice(1);
    if (lang.length >= 4) return lang;
  }
  return null;
}

// ---- Question banks (English base)
const Q_CAL = [
  // NOTE: First question is INTRO + stage combined to remove any “skipping”
  { id:"cal_stage", text:"We will conduct an airline interview simulation. Please answer using real examples from your experience. What stage are you currently at in your aviation career (student/CPL/IR etc.)?" },
  { id:"cal_hours", text:"Approximately how many flight hours do you have?" },
  { id:"cal_prev",  text:"Have you previously attended airline interviews? If yes, how far did you get in the process?" }
];

const Q_HR = [
  { id:"hr_about", text:"Tell me about yourself." },
  { id:"hr_why_airline", text:"Why do you want to work for this airline?" },
  { id:"hr_why_you", text:"Why should we select you?" },
  { id:"hr_dev", text:"What is one development area you are currently working on?" }
];

const Q_BEH = [
  { id:"beh_safety",  text:"Describe a time you had to follow rules or SOP strictly even when it was inconvenient. What happened and what did you do?" },
  { id:"beh_decision",text:"Describe a situation where you had to make a decision under time pressure. What options did you consider and what triggered your final decision?" },
  { id:"beh_risk",    text:"Describe a time you identified a risk early. How did you assess it and what action did you take to manage it?" },
  { id:"beh_comm",    text:"Describe a time you had to communicate critical information clearly under pressure. How did you ensure it was understood?" },
  { id:"beh_crm",     text:"Describe a situation where teamwork or CRM made a clear difference. What was your role and what did you do?" },
  { id:"beh_stress",  text:"Describe a time you faced high workload or stress. How did you prioritize and manage workload?" },
  { id:"beh_self",    text:"Describe a time you made a mistake or your performance fell short. What did you learn and what changed afterwards?" },
  { id:"beh_prof",    text:"Describe a time professionalism or reliability mattered. What was at stake and how did you behave?" }
];

const TECH_L1 = [
  "What is the difference between DA and MDA?",
  "What defines a stabilized approach?",
  "What is the purpose of the sterile cockpit rule?",
  "What are the responsibilities of pilot flying vs pilot monitoring?"
];
const TECH_L2 = [
  "What is the difference between V1 and V2?",
  "What factors affect takeoff performance?",
  "What is contingency fuel and why is it used?",
  "What is threat and error management in practice?",
  "What is situational awareness and how can it degrade?"
];
const TECH_L3 = [
  "What is balanced field length?",
  "What happens if an engine fails after V1?",
  "When must a destination alternate be nominated?",
  "What conditions are most conducive to airframe icing?",
  "What is RVSM and why is it important?",
  "What is the difference between CAT I and CAT III approach?"
];

const Q_MOT = [
  { id:"mot_1", text:"Where do you see yourself in five years?" },
  { id:"mot_2", text:"What do you think will be most challenging about airline life?" },
  { id:"mot_3", text:"What might cause you to leave an airline?" }
];

// ---- Behavioural gating
const NONANSWER_PATTERNS = [
  "i don't know","idk","never","i have never","can't think","no example",
  "en tiedä","en osaa","en ole koskaan","en ole ikinä","ei tule mieleen","ei oo kokemusta","ei ole kokemusta",
  "vaikea sanoa","en muista"
];
function isNonAnswer(text){
  const n = normalize(text);
  if (!n) return true;
  if (n.length < 18) return true;
  return NONANSWER_PATTERNS.some(p => n.includes(p));
}
function detectExample(text){
  const n = normalize(text);
  return ["once","one time","when i","i was","we were","i had to","i decided","kerran","tilanne","olin","jouduin","päätin","tapahtui"].some(c=>n.includes(c));
}
function detectOutcome(text){
  const n = normalize(text);
  return ["result","outcome","in the end","afterwards","learned","changed","lopputulos","tulos","sen jälkeen","opin","muutin"].some(c=>n.includes(c));
}
function countAnchors(text){
  const n = normalize(text);
  let a=0;
  if (["trigger","hard limit","criteria","minima","raja","laukaisi","kriteeri"].some(x=>n.includes(x))) a++;
  if (["option","alternative","considered","vaihtoehto","harkitsin"].some(x=>n.includes(x))) a++;
  if (["risk","trade-off","kompromissi","riski"].some(x=>n.includes(x))) a++;
  if (["communicat","brief","crm","told","kerroin","kommunikoin"].some(x=>n.includes(x))) a++;
  if (["learn","changed","next time","opin","muutin","jatkossa"].some(x=>n.includes(x))) a++;
  return a;
}
function resetGate(){ FLOW.gate = { hasExample:false, hasOutcome:false, anchors:0 }; }
function updateGate(t){
  FLOW.gate.hasExample = FLOW.gate.hasExample || detectExample(t);
  FLOW.gate.hasOutcome = FLOW.gate.hasOutcome || detectOutcome(t);
  FLOW.gate.anchors = Math.max(FLOW.gate.anchors, countAnchors(t));
}
function gatePassed(){ return FLOW.gate.hasExample && FLOW.gate.hasOutcome && FLOW.gate.anchors >= 2; }

function pickLevel(stageText, hoursText){
  const t = (stageText+" "+hoursText).toLowerCase();
  const m = t.match(/(\d{1,6})/);
  const hours = m ? parseInt(m[1], 10) : null;
  const advanced = ["cpl","atpl","ir","me","type","fo","captain"].some(k=>t.includes(k));
  if (hours !== null) {
    if (hours < 250 && !advanced) return 1;
    if (hours < 1200 && !t.includes("captain")) return 2;
    return 3;
  }
  return advanced ? 2 : 1;
}
function nextTechBank(){
  return (FLOW.level===3) ? TECH_L3 : (FLOW.level===2 ? TECH_L2 : TECH_L1);
}

// ---- WebRTC messaging
function sendEvent(obj){
  if (dc && dc.readyState === "open") dc.send(JSON.stringify(obj));
}

// Ask a question and ONLY THEN arm transcription acceptance
function askQuestion(id, englishText){
  if (FLOW.busyAsking) return;
  FLOW.busyAsking = true;
  FLOW.awaitingId = id;
  FLOW.armed = false; // will arm after assistant starts output

  const lang = FLOW.lang || "English";
  const mustKeep = ENGLISH_TERMS.join(", ");

  const instructions = `
LANGUAGE TARGET: ${lang}
TERMS MUST REMAIN ENGLISH (do NOT translate): ${mustKeep}

Task:
- Ask exactly ONE interview question.
- If LANGUAGE TARGET is not English, translate the question into that language, but keep the listed terms in English unchanged.
- Output ONLY the question. No filler, no commentary.

QUESTION:
${englishText}
`;

  sendEvent({ type:"response.create", response:{ modalities:["audio","text"], instructions } });
}

// Advance engine
function askNext(){
  if (FLOW.phase === 1) {
    const q = Q_CAL[FLOW.idx];
    if (!q) {
      FLOW.level = pickLevel(store.stage, store.hours);
      FLOW.phase=2; FLOW.idx=0;
      askNext(); return;
    }
    askQuestion(q.id, q.text);
    return;
  }
  if (FLOW.phase === 2) {
    const q = Q_HR[FLOW.idx];
    if (!q) { FLOW.phase=3; FLOW.idx=0; resetGate(); askNext(); return; }
    askQuestion(q.id, q.text);
    return;
  }
  if (FLOW.phase === 3) {
    const q = Q_BEH[FLOW.idx];
    if (!q) { FLOW.phase=4; FLOW.idx=0; askNext(); return; }
    askQuestion(q.id, q.text);
    return;
  }
  if (FLOW.phase === 4) {
    const bank = nextTechBank();
    const maxQ = Math.min(6, bank.length);
    if (FLOW.idx === 0) {
      askQuestion("tech_intro", "We will now move to a short technical segment.");
      FLOW.idx = 1;
      return;
    }
    const techIdx = FLOW.idx - 1;
    if (techIdx >= maxQ) { FLOW.phase=5; FLOW.idx=0; askNext(); return; }
    askQuestion(`tech_${techIdx+1}`, bank[techIdx]);
    return;
  }
  if (FLOW.phase === 5) {
    const q = Q_MOT[FLOW.idx];
    if (!q) {
      askQuestion("end", "This concludes the interview simulation. Thank you.");
      FLOW.phase=6;
      return;
    }
    askQuestion(q.id, q.text);
    return;
  }
}

// Handle user transcript ONLY when armed and awaitingId exists
function handleUserTranscript(rawText){
  const t = (rawText||"").trim();
  if (!FLOW.awaitingId) return;
  if (!FLOW.armed) return;            // <-- CRITICAL: ignore early/noise transcripts
  if (t.length < 2) return;

  const answerFor = FLOW.awaitingId;
  FLOW.awaitingId = null;
  FLOW.armed = false;
  FLOW.busyAsking = false;

  FLOW.transcript.push({ role:"user", text:t });

  const req = detectLanguageRequest(t);
  if (req) FLOW.lang = req;

  // Phase 1
  if (FLOW.phase === 1) {
    if (FLOW.idx === 0) store.stage = t;
    if (FLOW.idx === 1) store.hours = t;
    if (FLOW.idx === 2) store.prev  = t;
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 2 HR: always progress
  if (FLOW.phase === 2) {
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 3 behavioural: gated
  if (FLOW.phase === 3) {
    if (isNonAnswer(t)) {
      askQuestion("beh_gate_retry",
        "Please give a real example from another context (work, studies, sports, leadership, personal pressure). What happened and what did you do?");
      return;
    }
    updateGate(t);
    if (!FLOW.gate.hasExample) {
      askQuestion("beh_gate_ex", "Give one concrete situation: where were you, what happened, and what was your role?");
      return;
    }
    if (!FLOW.gate.hasOutcome) {
      askQuestion("beh_gate_out", "What was the outcome, and what changed afterwards?");
      return;
    }
    if (FLOW.gate.anchors < 2) {
      askQuestion("beh_gate_anchor", "What alternatives did you consider, and what was the objective trigger for your decision?");
      return;
    }
    resetGate();
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 4 tech + Phase 5 motivation: progress
  if (FLOW.phase === 4 || FLOW.phase === 5) {
    FLOW.idx++;
    askNext();
    return;
  }
}

// ---- WebRTC connect
async function getEphemeralKey(){
  const r = await fetch("/api/realtime-token", { method:"POST" });
  const j = await r.json().catch(()=>({}));
  const key = j?.client_secret?.value;
  if (!key) throw new Error("No client_secret.value from /api/realtime-token");
  return key;
}

function sessionUpdate(){
  sendEvent({
    type: "session.update",
    session: {
      modalities: ["audio","text"],
      instructions: SYSTEM,
      temperature: 0.6,
      voice: "alloy",
      input_audio_transcription: { model: "gpt-4o-mini-transcribe" },
      // Model does not auto-respond; we trigger responses
      turn_detection: { type: "semantic_vad", eagerness: "medium", create_response: false }
    }
  });
}

async function start(){
  startBtn.disabled=true;
  stopBtn.disabled=false;
  logEl.textContent="";
  setStatus("Starting...");

  // reset
  FLOW.lang="English";
  FLOW.phase=1;
  FLOW.idx=0;
  FLOW.level=2;
  FLOW.transcript=[];
  FLOW.awaitingId=null;
  FLOW.armed=false;
  FLOW.busyAsking=false;
  resetGate();
  store.stage=""; store.hours=""; store.prev="";

  const ephemeralKey = await getEphemeralKey();

  pc = new RTCPeerConnection();
  audioEl = document.createElement("audio");
  audioEl.autoplay = true;
  audioEl.playsInline = true;
  pc.ontrack = (e) => { audioEl.srcObject = e.streams[0]; };

  localStream = await navigator.mediaDevices.getUserMedia({ audio:true });
  localStream.getTracks().forEach(t=>pc.addTrack(t, localStream));

  dc = pc.createDataChannel("oai-events");
  dc.onopen = async () => {
    setStatus("Connected.");
    log("Connected.");

    sessionUpdate();

    // IMPORTANT: wait a bit so first audio is not clipped
    await new Promise(r=>setTimeout(r, 700));

    askNext();
  };

  dc.onmessage = (ev) => {
    let msg; try { msg = JSON.parse(ev.data); } catch { return; }

    if (msg.type === "error") log("ERROR: " + JSON.stringify(msg));

    // Arm transcript acceptance when assistant output actually starts
    if (msg.type === "response.output_audio.delta" || msg.type === "response.output_text.delta") {
      // Once we have any assistant output for the current question, arm input consumption
      FLOW.armed = true;
    }

    if (msg.type === "conversation.item.input_audio_transcription.completed") {
      const text = msg.transcript || "";
      handleUserTranscript(text);
    }
  };

  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);

  const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent("gpt-4o-realtime-preview")}`, {
    method:"POST",
    headers:{ Authorization:`Bearer ${ephemeralKey}`, "Content-Type":"application/sdp" },
    body: offer.sdp
  });

  const answerSdp = await sdpRes.text();
  await pc.setRemoteDescription({ type:"answer", sdp: answerSdp });

  setStatus("Realtime started. Speak.");
}

function stop(){
  stopBtn.disabled=true;
  startBtn.disabled=false;
  setStatus("Stopped.");

  try { if (dc) dc.close(); } catch {}
  try { if (pc) pc.close(); } catch {}
  dc=null; pc=null;

  try { if (localStream) localStream.getTracks().forEach(t=>t.stop()); } catch {}
  localStream=null;
}

startBtn.onclick = () => start().catch(e=>{
  console.error(e);
  alert(e?.message || String(e));
  log("START ERROR: " + (e?.message || String(e)));
  stop();
});
stopBtn.onclick = stop;
</script>
</body>
</html>

