<!doctype html>
<html>
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <title>Airline Interview AI (Voice)</title>
  <style>
    body { font-family: system-ui, -apple-system, Segoe UI, Roboto, Arial; margin: 18px; }
    button { padding: 10px 14px; margin-right: 10px; }
    #status { margin-top: 10px; opacity: 0.85; }
    #log { margin-top: 10px; white-space: pre-wrap; font-size: 12px; opacity: 0.8; max-height: 45vh; overflow:auto; background:#f6f6f6; padding:10px; border-radius:8px;}
  </style>
</head>
<body>
  <h1>Airline Interview AI (Voice)</h1>
  <button id="startBtn">Start interview</button>
  <button id="stopBtn" disabled>Stop</button>
  <div id="status">Idle</div>
  <div id="log"></div>

<script>
/**
 * What this version guarantees:
 * - Default language English. Switch to ANY language only if candidate explicitly asks.
 * - Aviation/technical terms ALWAYS remain English (never translated).
 * - The model NEVER freestyles interview structure: client controls the flow.
 * - Anti-speedrun gate: if answer is weak/non-answer -> it does NOT progress.
 * - No coaching during interview. Debrief at the end.
 */

const startBtn = document.getElementById("startBtn");
const stopBtn  = document.getElementById("stopBtn");
const statusEl = document.getElementById("status");
const logEl    = document.getElementById("log");
const setStatus = (s) => statusEl.textContent = s;
const log = (s) => { logEl.textContent = (logEl.textContent + s + "\n").slice(-14000); };

let pc=null, dc=null, localStream=null, audioEl=null;

// ---- Terms that must remain English always
const ENGLISH_TERMS = [
  "V1","V2","balanced field length","accelerate-stop distance","stabilized approach",
  "DA","MDA","contingency fuel","alternate fuel","windshear",
  "threat and error management","situational awareness","sterile cockpit",
  "RVSM","CAT I","CAT III","pilot flying","pilot monitoring"
];

// ---- Session system instructions (short + strict)
// NOTE: we do NOT rely on the model to enforce structure; we enforce structure in this client.
const SYSTEM = `
You are a three-member airline interview panel conducting a realistic airline screening interview simulation for a pilot role.

DEFAULT LANGUAGE:
- Default language is English.
- Switch to the candidate’s requested language ONLY if the candidate explicitly asks.
- If a language is requested, ask questions in that language.

TERMS:
- Keep ALL aviation/technical terms in English and do NOT translate them.
- Examples that must remain English: ${ENGLISH_TERMS.join(", ")}.

OUTPUT RULES:
- Output ONLY the question requested by the client instructions.
- Ask ONE question at a time.
- Do NOT add commentary, explanations, coaching, or advice.
- No filler acknowledgements (e.g., "thank you", "okay", "understood", "kiitos", "ymmärretty").
- If candidate asks for help: reply exactly:
  "In a real airline interview I cannot coach you. Please answer using a real example."
`;

// ---- Flow state
const FLOW = {
  lang: "English",        // default
  phase: 1,               // 1 calibration, 2 HR, 3 behavioural, 4 technical, 5 motivation, 6 debrief
  idx: 0,
  level: 2,               // will be estimated after calibration
  followupsLeft: 0,
  lastPrimaryId: null,
  // gating for behavioural questions
  gate: { hasExample:false, hasOutcome:false, anchors:0, attempts:0 },
  // store answers for debrief
  transcript: []
};

// ---- Question sets (primary questions)
const Q_CAL = [
  { id:"cal_intro", text:`We will conduct an airline interview simulation. Please answer using real examples from your experience.` , isStatement:true },
  { id:"cal_stage", text:"What stage are you currently at in your aviation career (student/CPL/IR etc.)?" },
  { id:"cal_hours", text:"Approximately how many flight hours do you have?" },
  { id:"cal_prev",  text:"Have you previously attended airline interviews? If yes, how far did you get in the process?" }
];

const Q_HR = [
  { id:"hr_about", text:"Tell me about yourself." },
  { id:"hr_why_airline", text:"Why do you want to work for this airline?" },
  { id:"hr_why_you", text:"Why should we select you?" },
  { id:"hr_dev", text:"What is one development area you are currently working on?" }
];

// 8 competencies (one primary each) — no passenger/cabin-career-advice nonsense
const Q_BEH = [
  { id:"beh_safety", text:"Describe a time you had to follow rules or SOP strictly even when it was inconvenient. What happened and what did you do?" },
  { id:"beh_decision", text:"Describe a situation where you had to make a decision under time pressure. What options did you consider and what triggered your final decision?" },
  { id:"beh_risk", text:"Describe a time you identified a risk early. How did you assess it and what action did you take to manage it?" },
  { id:"beh_comm", text:"Describe a time you had to communicate critical information clearly under pressure. How did you ensure it was understood?" },
  { id:"beh_crm", text:"Describe a situation where teamwork or CRM made a clear difference to the outcome. What was your role and what did you do?" },
  { id:"beh_stress", text:"Describe a time you faced high workload or stress. How did you prioritize and manage workload?" },
  { id:"beh_self", text:"Describe a time you made a mistake or your performance fell short. What did you learn and what changed afterwards?" },
  { id:"beh_prof", text:"Describe a time professionalism or reliability mattered. What was at stake and how did you behave?" }
];

// Technical banks (choose 4–6; keep terms English)
const TECH_L1 = [
  "What is the difference between DA and MDA?",
  "What defines a stabilized approach?",
  "What is the purpose of the sterile cockpit rule?",
  "What are the responsibilities of pilot flying vs pilot monitoring?"
];
const TECH_L2 = [
  "What is the difference between V1 and V2?",
  "What factors affect takeoff performance?",
  "What is contingency fuel and why is it used?",
  "What is threat and error management in practice?",
  "What is situational awareness and how can it degrade?"
];
const TECH_L3 = [
  "What is balanced field length?",
  "What happens if an engine fails after V1?",
  "When must a destination alternate be nominated?",
  "What conditions are most conducive to airframe icing?",
  "What is RVSM and why is it important?",
  "What is the difference between CAT I and CAT III approach?"
];

const Q_MOT = [
  { id:"mot_5y", text:"Where do you see yourself in five years?" },
  { id:"mot_challenge", text:"What do you think will be most challenging about airline life?" },
  { id:"mot_leave", text:"What might cause you to leave an airline?" }
];

// ---- Helpers: language switch detection
function normalize(s){ return (s||"").toLowerCase().replace(/\s+/g," ").trim(); }

function detectLanguageRequest(userText){
  const t = normalize(userText);
  // common patterns
  if (t.includes("suomeksi") || t.includes("in finnish") || t.includes("finnish")) return "Finnish";
  if (t.includes("englanniksi") || t.includes("in english") || t.includes("english")) return "English";
  // generic: "in Spanish", "in German", "in French", etc.
  const m = t.match(/\bin ([a-zäöå]+)\b/);
  if (m && m[1]) {
    // crude normalize capitalization
    const lang = m[1].charAt(0).toUpperCase() + m[1].slice(1);
    // avoid false positives like "in a"
    if (lang.length >= 4) return lang;
  }
  return null;
}

// ---- Anti-speedrun gate (behavioural)
const NONANSWER_PATTERNS = [
  "i don't know","idk","never","i have never","can't think","no example",
  "en tiedä","en osaa","en ole koskaan","en ole ikinä","ei tule mieleen","ei oo kokemusta","ei ole kokemusta",
  "vaikea sanoa","en muista"
];

function isNonAnswer(text){
  const n = normalize(text);
  if (!n) return true;
  if (n.length < 18) return true;
  return NONANSWER_PATTERNS.some(p => n.includes(p));
}

function detectExample(text){
  const n = normalize(text);
  const cues = ["once","one time","when i","i was","we were","i had to","i decided","the situation","at that time",
                "kerran","tilanne","olin","me olimme","jouduin","päätin","tapahtui","silloin"];
  return cues.some(c => n.includes(c));
}
function detectOutcome(text){
  const n = normalize(text);
  const cues = ["result","outcome","in the end","afterwards","we ended up","learned","changed",
                "lopputulos","tulos","sen jälkeen","päädyimme","opin","muutin"];
  return cues.some(c => n.includes(c));
}
function countAnchors(text){
  const n = normalize(text);
  let a = 0;
  if (["trigger","hard limit","gate","criteria","minima","raja","laukaisi","kriteeri"].some(x=>n.includes(x))) a++;
  if (["option","alternative","considered","vaihtoehto","harkitsin"].some(x=>n.includes(x))) a++;
  if (["risk","trade-off","kompromissi","riski"].some(x=>n.includes(x))) a++;
  if (["communicat","brief","crm","told","said","kerroin","kommunikoin","briefasin"].some(x=>n.includes(x))) a++;
  if (["learn","changed","next time","opin","muutin","jatkossa"].some(x=>n.includes(x))) a++;
  return a;
}

function resetGate(){ FLOW.gate = { hasExample:false, hasOutcome:false, anchors:0, attempts:0 }; }
function updateGateFromAnswer(text){
  FLOW.gate.hasExample = FLOW.gate.hasExample || detectExample(text);
  FLOW.gate.hasOutcome = FLOW.gate.hasOutcome || detectOutcome(text);
  FLOW.gate.anchors = Math.max(FLOW.gate.anchors, countAnchors(text));
}
function gatePassed(){ return FLOW.gate.hasExample && FLOW.gate.hasOutcome && FLOW.gate.anchors >= 2; }

// ---- Determine level after calibration
function pickLevel(stageText, hoursText){
  const t = (stageText+" "+hoursText).toLowerCase();
  const m = t.match(/(\d{1,6})/);
  const hours = m ? parseInt(m[1], 10) : null;
  const advanced = ["cpl","atpl","ir","me","type","fo","captain"].some(k=>t.includes(k));
  if (hours !== null) {
    if (hours < 250 && !advanced) return 1;
    if (hours < 1200 && !t.includes("captain")) return 2;
    return 3;
  }
  return advanced ? 2 : 1;
}

// ---- WebRTC helpers
function sendEvent(obj){
  if (dc && dc.readyState === "open") dc.send(JSON.stringify(obj));
}

/**
 * askQuestion:
 * - If FLOW.lang is English: ask exactly in English.
 * - If not: instruct model to translate the English question into requested language,
 *   while keeping aviation terms in English.
 */
function askQuestion(englishText, opts={}){
  const lang = FLOW.lang || "English";

  const mustKeep = ENGLISH_TERMS.join(", ");
  const base = `
LANGUAGE TARGET: ${lang}
TERMS MUST REMAIN ENGLISH: ${mustKeep}

Your task:
- Ask exactly ONE interview question.
- No acknowledgements. No commentary.
- If LANGUAGE TARGET is not English: translate the question into that language, but keep the listed terms in English unchanged.
- Output only the question text.
`;

  const content = opts.preface
    ? `${base}\n${opts.preface}\nQUESTION:\n${englishText}`
    : `${base}\nQUESTION:\n${englishText}`;

  sendEvent({
    type: "response.create",
    response: {
      modalities: ["audio","text"],
      instructions: content
    }
  });
}

// ---- Interview engine
const store = { stage:"", hours:"", prev:"" };

function nextTechnicalBank(){
  return (FLOW.level===3) ? TECH_L3 : (FLOW.level===2 ? TECH_L2 : TECH_L1);
}

function askNext(){
  // Phase 1: calibration
  if (FLOW.phase === 1) {
    const q = Q_CAL[FLOW.idx];
    if (!q) {
      FLOW.level = pickLevel(store.stage, store.hours);
      FLOW.phase = 2; FLOW.idx = 0;
      askNext(); return;
    }
    // intro statement + first question
    if (q.isStatement) {
      askQuestion(q.text, { preface: "Say this line exactly, then wait." });
      FLOW.idx++; // next call will ask cal_stage
      // Immediately ask the first calibration question as a separate turn:
      setTimeout(() => askQuestion(Q_CAL[FLOW.idx].text), 250);
      return;
    }
    askQuestion(q.text);
    return;
  }

  // Phase 2: HR
  if (FLOW.phase === 2) {
    const q = Q_HR[FLOW.idx];
    if (!q) { FLOW.phase=3; FLOW.idx=0; resetGate(); askNext(); return; }
    askQuestion(q.text);
    return;
  }

  // Phase 3: Behavioural (gated)
  if (FLOW.phase === 3) {
    const q = Q_BEH[FLOW.idx];
    if (!q) { FLOW.phase=4; FLOW.idx=0; askNext(); return; }
    askQuestion(q.text);
    return;
  }

  // Phase 4: Technical (4–6 questions)
  if (FLOW.phase === 4) {
    const bank = nextTechnicalBank();
    const maxQ = Math.min(6, bank.length); // cap 6
    if (FLOW.idx === 0) {
      askQuestion("We will now move to a short technical segment.", { preface: "Say this line exactly as written." });
      FLOW.idx++; // next will be first tech question
      setTimeout(() => askQuestion(bank[0]), 250);
      return;
    }
    const techIdx = FLOW.idx - 1;
    if (techIdx >= maxQ) { FLOW.phase=5; FLOW.idx=0; askNext(); return; }
    askQuestion(bank[techIdx]);
    return;
  }

  // Phase 5: Motivation
  if (FLOW.phase === 5) {
    const q = Q_MOT[FLOW.idx];
    if (!q) { FLOW.phase=6; FLOW.idx=0; startDebrief(); return; }
    askQuestion(q.text);
    return;
  }
}

function startDebrief(){
  const lang = FLOW.lang || "English";
  const mustKeep = ENGLISH_TERMS.join(", ");

  const transcriptText = FLOW.transcript
    .slice(-120) // safety cap
    .map(x => `${x.role.toUpperCase()}: ${x.text}`)
    .join("\n");

  const instructions = `
You are now in DEBRIEF MODE.

LANGUAGE:
- Write the debrief in ${lang}.
- Keep aviation/technical terms in English: ${mustKeep}

Rules:
- Professional, analytical, constructive.
- No praise. No humiliation. No model answers.
- Be specific about what was missing if answers were weak or generic.

Output the debrief with these headings:

#1 Overall Impression
- Readiness level (Early / Developing / Competitive / Strong)
- Main strengths
- Main development areas

#2 Behavioural Evaluation
Assess:
- Safety & risk thinking
- Decision structure
- Use of concrete triggers
- Communication clarity
- CRM awareness
- Stress handling
- Self-awareness
For each:
- What worked
- Where answers were too general
- Where clearer decision gates were needed

#3 Technical Evaluation
- Conceptual understanding
- Operational reasoning
- Depth relative to experience level

#4 Interview Behaviour
- Structure of answers
- Clarity
- Conciseness
- Logical flow
- Confidence

#5 Priority Development Plan
Provide 3–5 specific training priorities (no motivational fluff).

Here is the interview transcript:
${transcriptText}
`;

  sendEvent({
    type: "response.create",
    response: { modalities: ["audio","text"], instructions }
  });
}

function handleUserTranscript(text){
  const t = (text||"").trim();
  if (!t) return;

  FLOW.transcript.push({ role:"user", text:t });

  // language request handling (works anytime)
  const req = detectLanguageRequest(t);
  if (req) FLOW.lang = req;

  // Phase 1 store calibration
  if (FLOW.phase === 1) {
    // idx currently points to next question to ask, but user answered previous one.
    // We infer based on idx value progression.
    // After intro, we asked stage (idx=1). When user answers stage, we should store stage, etc.
    // We'll store sequentially:
    if (!store.stage) store.stage = t;
    else if (!store.hours) store.hours = t;
    else if (!store.prev) store.prev = t;

    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 2 HR: light probing but always progress (one follow-up could be added later)
  if (FLOW.phase === 2) {
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 3 Behavioural: gating (THIS is the anti-speedrun)
  if (FLOW.phase === 3) {
    // If totally non-answer: do not progress. Force example from other context.
    if (isNonAnswer(t)) {
      askQuestion(
        "Please give a real example from another context (work, studies, sports, leadership, personal pressure). What happened and what did you do?",
        { preface: "Do NOT progress. The candidate has not provided a usable example." }
      );
      return;
    }

    updateGateFromAnswer(t);

    if (!FLOW.gate.hasExample) {
      askQuestion("Give one concrete situation: where were you, what happened, and what was your role?");
      return;
    }
    if (!FLOW.gate.hasOutcome) {
      askQuestion("What was the outcome, and what changed afterwards?");
      return;
    }
    if (FLOW.gate.anchors < 2) {
      askQuestion("What alternatives did you consider, and what was the objective trigger for your decision?");
      return;
    }

    // Passed gate -> progress to next competency
    resetGate();
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 4 technical: progress
  if (FLOW.phase === 4) {
    FLOW.idx++;
    askNext();
    return;
  }

  // Phase 5 motivation: progress
  if (FLOW.phase === 5) {
    FLOW.idx++;
    askNext();
    return;
  }
}

// ---- WebRTC start/stop
async function getEphemeralKey(){
  const r = await fetch("/api/realtime-token", { method:"POST" });
  const j = await r.json().catch(()=>({}));
  const key = j?.client_secret?.value;
  if (!key) throw new Error("No client_secret.value from /api/realtime-token");
  return key;
}

function sessionUpdate(){
  sendEvent({
    type: "session.update",
    session: {
      modalities: ["audio","text"],
      instructions: SYSTEM,
      temperature: 0.6,
      voice: "alloy",
      input_audio_transcription: { model: "gpt-4o-mini-transcribe" },
      // Critical: model does NOT auto-respond; we trigger responses
      turn_detection: { type: "semantic_vad", eagerness: "medium", create_response: false }
    }
  });
}

async function start(){
  startBtn.disabled = true;
  stopBtn.disabled = false;
  logEl.textContent = "";
  setStatus("Starting...");

  // reset flow
  FLOW.lang = "English";
  FLOW.phase = 1; FLOW.idx = 0;
  FLOW.level = 2;
  FLOW.transcript = [];
  resetGate();
  store.stage=""; store.hours=""; store.prev="";

  const ephemeralKey = await getEphemeralKey();

  pc = new RTCPeerConnection();
  audioEl = document.createElement("audio");
  audioEl.autoplay = true;
  audioEl.playsInline = true;
  pc.ontrack = (e) => { audioEl.srcObject = e.streams[0]; };

  localStream = await navigator.mediaDevices.getUserMedia({ audio:true });
  localStream.getTracks().forEach(t => pc.addTrack(t, localStream));

  dc = pc.createDataChannel("oai-events");
  dc.onopen = () => {
    setStatus("Connected.");
    log("Connected (data channel open).");

    sessionUpdate();

    // Kick off first prompt
    askNext();
  };

  dc.onmessage = (ev) => {
    let msg; try { msg = JSON.parse(ev.data); } catch { return; }
    if (msg.type === "error") log("ERROR: " + JSON.stringify(msg));

    if (msg.type === "conversation.item.input_audio_transcription.completed") {
      const text = msg.transcript || msg.text || "";
      FLOW.transcript.push({ role:"user", text });
      handleUserTranscript(text);
    }

    // Store assistant outputs for debrief context if needed
    if (msg.type === "response.output_text.delta") {
      // optional: not needed
    }
  };

  const offer = await pc.createOffer();
  await pc.setLocalDescription(offer);

  const sdpRes = await fetch(`https://api.openai.com/v1/realtime?model=${encodeURIComponent("gpt-4o-realtime-preview")}`, {
    method: "POST",
    headers: { Authorization: `Bearer ${ephemeralKey}`, "Content-Type": "application/sdp" },
    body: offer.sdp
  });

  const answerSdp = await sdpRes.text();
  await pc.setRemoteDescription({ type:"answer", sdp: answerSdp });

  setStatus("Realtime started. Speak.");
}

function stop(){
  stopBtn.disabled = true;
  startBtn.disabled = false;
  setStatus("Stopped.");

  try { if (dc) dc.close(); } catch {}
  try { if (pc) pc.close(); } catch {}
  dc=null; pc=null;

  try { if (localStream) localStream.getTracks().forEach(t=>t.stop()); } catch {}
  localStream=null;
}

startBtn.onclick = () => start().catch(e => {
  console.error(e);
  alert(e?.message || String(e));
  log("START ERROR: " + (e?.message || String(e)));
  stop();
});
stopBtn.onclick = stop;
</script>
</body>
</html>
